#+title: Code ToDo
* [ ] Runner
** [X] When persisting state for LLM, we need to differentiate answers from user inputs. This makes model hallucinate.
** [X] ctrl+c after providing looping llm answer did not continue from that step - it started from initial step.
** [X] Change executors to have explicit state
** [X] Stop/Resume should work off activities
** [X] Rewind should work off activities
** [X] When looping on the same node - we need to append message to existing history. Update protocol to return user input back to executor without creating a new executor instance and losing a lot of function call context.
** [X] Add tool calling support
** [X] Allow edges to control history retainment value
** [ ] Add a way to raise error and stop the runner. User should be able to try and continue the runner.
** [X] Investigate stopping and cancelation of existing runners
** [X] Figure out if we can store node reset semantics at the edge level? So failure might keep the state, but initial entry should not?
- Patch node failing and going back to coder should persist coder state and append patch error
** [X] Figure out why final messages can be duplicated sometimes
** [ ] Move replace_last_message logic to UIState from runner
** [X] Add VIM mode
** [X] Add multi-line input
** [X] Add a flag to not show node output in the UI. Useful for input node, etc
** [ ] Add a way to restrict number of loops when cycling
** [ ] Stopping executor with ctrl+c during input and then starting it with /use does not stop at input, but retries last input node
** [X] It seems like reset_policy: keep_results is keeping more than a single result. Maybe it should, but then we need keep_final policy too.
* [ ] Configuration
** [X] Redo include file syntax to include section with default variable values
** [ ] Update templates and parametrize them via variables
** [ ] Figure out why confirmation override for discovery did not work
** [ ] Tweak architect prompts to not provide solution if there are questions to answer or user explicitly requests one shot solution
** [ ] Tweak prompt for discovery to only work with existing files
* [ ] Add a way for executors to pass state between nodes, even if nodes are different but of same type
Concrete example: files that were read and already in context.
* [ ] Error handling
** [ ] Tool calling timeouts and failures
** [ ] Add a way for human to unblock failures by retrying last operation
* [ ] Cleanup all dependencies
** [X] Move graph models out of graph, move runtime graph generation out of Graph class
** [X] Move executor/models.py out to root
** [X] Move preprocessors to llm/ and move llm.py to llm/__init__.py
* [X] UI protocol
** [X] In-memory bidirectional stream implementation for TUI
** [ ] Add syntax name hint to apply formatting
* [ ] Terminal UI
** [ ] Simple styling
*** [ ] Color usage
*** [ ] Separate tool calls from outputs
*** [ ] Remove Agent: prefix
** [ ] Print node transitions
** [ ] Format tool calls
** [ ] Assume markdown as default formatter
** [ ] Wrapped lines don't move caret down correctly - next line overwrites it.
** [X] Add way to show log messages (inline? out of process?)
** [X] Fix line breaks - if line is naturally too long, then moving caret to the beginning of the line does not work, we need to go one line up.
** [X] Fix intermediate response streaming
** [X] Remove (or disable) prompt when input is not requested
** [X] Fix prompt display - it's not visible after output
** [X] Fix prompt text, it's not showing correct current node or requested text
** [ ] Disable input and drop buffered input between prompts
** [ ] Change workflow execution:
- If workflow is selected, first message sent should start the workflow
- If workflow is stopped after finishing, then sending a new message should resume same workflow from the beginning
- If workflow is canceled, then workflow should start new workflow
** [X] ctrl+c when runner is active does nothing - should stop the runner (verify, might not be the case)
** [ ] We might have deadlock somewhere that does not break with ctrl+c
- Added debugging stacktraces for now
** [X] Add file context management once corresponding node is created
** [ ] Add file and symbol auto-completes for a last word. Call into Know to do lookup and return most likely candidates. Maybe get complete file and symbol list from Know and create in-memory trigram index for quick lookups.
** [X] Add approximate cost calculator and output
** [X] Add toolbar that shows current cost and mode of operation
** [ ] Fix estimated cost calculation
** [ ] Highlighting does not work if ``` opener is not in the beginning of the line
* [ ] Tools
** [ ] Integrate Know
*** [X] Needs a separate execution thread and simple async API wrapper RPC, as it is synchronous
- Take callable function as a parameter, run it in Know thread, return results back
*** [ ] Add progress report
** [X] Add a way to auto-approve tool calls
** [ ] Add pattern matching rules to auto-approve rule calls
* [ ] Block parsers
** [X] Code parsers
** [ ] Diff parsers
*** [ ] GPT V4A diff format
**** [X] Better error reporting and verify apply patch cycle
**** [X] When multiple chunks match, but we can't match any of the chunks - return all possible lines
**** [X] Add support for multi-blocks where multiple things are getting deleted and added.
**** [X] Add support for multiple patch blocks or provide better instructions
**** [ ] Allow multiple patches in a single request
*** [X] Fenced diff format
*** [ ] Unified Diff format
* [X] Settings
** [X] Settings loader
* [ ] Chat state
** [X] NodeLog, Section, Message
* [ ] Nodes
** [X] Add project as a parameter to executor
** [ ] Add a node that injects files in context. Add file manager.
*** [ ] Add file context manager
*** [ ] Add UI support for file context management
** [X] [#A] Think how to manage state for a run
** [X] Base node runner class
** [ ] LLM node
*** [X] Base
**** [X] Tool configuration
- Integrate Know
**** [X] Exposing available tools to LLM from project
**** [X] Implement tool calling
*** [X] Verify if we're including files multiple times in responsing, thus burning tokens
*** [X] Limit context length and reject tool calls when over
*** [X] Prevent too many files to be read
*** [X] Dynamic output selection by LLM
**** [X] Configurable system prompt extension
**** [X] Cleanup logic
**** [X] Re-prompt if answer is not provided
**** [X] Add non-function way of picking next step
**** [X] Add a way for LLM to request additional user input
*** [X] Do not add empty message to output
*** [ ] Auto-retry on timeout
*** [ ] Auto-retry when throttled
*** [X] For some reason tokens are not accumulated for tool calls
*** [ ] Figure out why pricing estimates are all zeroes
** [X] Diff apply node
*** [X] Base parser
*** [X] Add a way to write file changes after confirmation
*** [X] Tell Know that files were updated and project needs to be updated
*** [X] Handle all kind of errors - mismatched chunks, etc
*** [X] Add patch tool mode for V4A specifically. It double-escapes everything quoted.
*** [X] Move prompts to patcher implementations
** [ ] Create RepoMap node - call into Know with provided prompt
** [ ] Create documentation node - read AGENT.md files for all paths that are mentioned in previous messages.
- Have configuration for static message text
- Support one or more explicit paths to be read and inserted into message context
- Append to previous message
- How do we extract paths reliably?
- Maybe offer a tool?
** [ ] Fan-out node - call other defined tools, collect their results and pass concatenated messages to next tool
** [ ] TODO node - collect plan that is formatted with specific syntax (markdown? function call?
* [ ] Tools
** [ ] MCP tool support
** [ ] Add a way to reject tool calling automatically if tools with same parameters were already called
* [ ] Nested workflows support
** [ ] Create API to start a new workflow
- Should start a runner
- Wait for runner to finish
- Pass all messages through to UI
* [X] Graph
** [X] Rename output to be outcome
** [X] Refactor NodeExecution input_messages and messages. messages should be append only.
** [X] Add a way to override values from a shared config. Options:
- Through special value
- Though path in the settings of <tool_name.node_name.field_name> syntax
- Both?
- Also read from files when file is defined
** [X] Add a way to get node definition from template and override some of the fields from config
** [X] Graph runner
** [X] Add a way to rewind history back to resume from a different point
