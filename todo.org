#+title: Code ToDo

* [ ] Cleanup all dependencies
- Move graph models out of graph, move runtime graph generation out of Graph class
- Move executor/models.py out to root
- Move preprocessors to llm/ and move llm.py to llm/__init__.py
* [X] UI protocol
** [X] In-memory bidirectional stream implementation for TUI
* [ ] Terminal UI
** [ ] Add logging
** [X] Fix intermediate response streaming
** [X] Remove (or disable) prompt when input is not requested
** [X] Fix prompt display - it's not visible after output
** [X] Fix prompt text, it's not showing correct current node or requested text
** [ ] Disable input and drop buffered input between prompts
** [ ] Change workflow execution:
- If workflow is selected, first message sent should start the workflow
- If workflow is stopped after finishing, then sending a new message should resume same workflow from the beginning
- If workflow is canceled, then workflow should start new workflow
** [ ] ctrl+c when runner is active does nothing - should stop the runner (verify, might not be the case)
** [ ] Add file context management once corresponding node is created
** [ ] Add file and symbol auto-completes for a last word. Call into Know to do lookup and return most likely candidates. Maybe get complete file and symbol list from Know and create in-memory trigram index for quick lookups.
* [ ] Tools
** [ ] Integrate Know
*** [ ] Needs a separate execution thread and simple async API wrapper RPC, as it is synchronous
- Take callable function as a parameter, run it in Know thread, return results back
* [ ] Graph
** [X] Rename output to be outcome
** [X] Refactor NodeExecution input_messages and messages. messages should be append only.
** [X] Add a way to override values from a shared config. Options:
- Through special value
- Though path in the settings of <tool_name.node_name.field_name> syntax
- Both?
- Also read from files when file is defined
** [X] Add a way to get node definition from template and override some of the fields from config
** [X] Graph runner
** [X] Add a way to rewind history back to resume from a different point
* [ ] Block parsers
** [X] Code parsers
** [ ] Diff parsers
*** [X] GPT V4A diff format
*** [ ] Fenced diff format
*** [ ] Full file diff format
* [X] Settings
** [X] Settings loader
* [ ] Chat state
** [X] NodeLog, Section, Message
* [ ] Nodes
** [X] Add project as a parameter to executor
** [ ] Add a node that injects files in context. Add file manager.
** [ ] [#A] Think how to manage state for a run
- Sometimes we need to maintain the state when additional information is found and added to state
- Sometimes we need to start fresh
- But need to maintain state if looped by human
- Most likely make it a setting of a Node (explicit config). Via enum?
  - Always resets
  - Human resets
  - Robot resets
  - Never resets
- We need machinery to go back in time and reset graph execution to a specific history
** [X] Base node runner class
** [ ] LLM node
*** [?] Base
**** [ ] Tool configuration
- Integrate Know
**** [ ] Exposing available tools to LLM from project
*** [X] Dynamic output selection by LLM
**** [X] Configurable system prompt extension
**** [X] Cleanup logic
**** [X] Re-prompt if answer is not provided
**** [X] Add non-function way of picking next step
**** [X] Add a way for LLM to request additional user input
*** [X] Do not add empty message to output
*** [ ] Auto-retry on timeout
*** [ ] Auto-retry when throttled
** [ ] Diff apply node
*** [X] Base parser
*** [ ] Add a way to write file changes after confirmation
*** [ ] Tell Know that files were updated and project needs to be updated
** [ ] Create RepoMap node - call into Know with provided prompt
** [ ] Create documentation node - read AGENT.md files for all paths that are mentioned in previous messages.
- Have configuration for static message text
- Support one or more explicit paths to be read and inserted into message context
- Append to previous message
- How do we extract paths reliably?
- Maybe offer a tool?
** [ ] Fan-out node - call other defined tools, collect their results and pass concatenated messages to next tool
** [ ] TODO node - collect plan that is formatted with specific syntax (markdown? function call?
* [ ] Nested workflows support
** [ ] Create API to start a new workflow
- Should start a runner
- Wait for runner to finish
- Pass all messages through to UI
